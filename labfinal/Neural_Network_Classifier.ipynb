{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidade Federal de Campina Grande \n",
    "# Unidade acadêmica de Sistemas e Computação - Pós-graduação \n",
    "# Professor: Leandro Balby\n",
    "# Machine Learning 2017.2\n",
    "# Aluno:  Caio Batista Oliveira "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de violações de design em programas de alunos utilizando  redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tema do meu mestrado tem como princípio testes de identificação de violações de padrão de design para programas dos alunos da disciplina de <b>Programação 1</b>. E a ideia inicial deste projeto para a disciplina de Machine Learnin era fazer uma classificação de um programa conforme sua unidade da disciplina, entretanto uma ideia que fazia mais sentido era mudar o foco para a detecção de violação de programas de uma forma baseada em dados. Foi então que mudei o projeto para fazer uma classificação especificamente entre <b>Violação</b> e <b>Não-violação</b> de programas especificamente da unidade 7. A escolha dessa unidade foi dada por ter uma grande margem para utilização de funções e operações sobre listas, o problema mais recorrente na pesquisa do mestrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questão da classificação fica mais fácil de ser compreendida com exeplos, então a seguir temos a lista de funções proibidas e logo abaixo 3 exemplos e suas respectivas classificações com uma curta explicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ replace\n",
    "+ count \n",
    "+ index\n",
    "+ sort \n",
    "+ min \n",
    "+ max\n",
    "+ join\n",
    "+ sum\n",
    "+ strip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Exemplo - Neste exemplo não existe violação, a iteração sobre a lista é permitida e o acumulo na variável também. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Não-violação \n",
    "\n",
    "def exemplo1(lista):\n",
    "    soma = 0\n",
    "    for i in range(len(lista)):\n",
    "        soma += lista[i]\n",
    "\n",
    "    return soma    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Exemplo - Neste exemplo temos uma violação na ordenação da lista, pois a operação <b>Sort</b> não é permitida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Violação \n",
    "\n",
    "def exemplo2(lista):\n",
    "    return lista.sort()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Exemplo - Aqui neste último exemplo temos uma violação. Apesar da operação <b>Split</b> ser permitida, o <b>Join</b> não é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Violação \n",
    "\n",
    "def exemplo3(string):\n",
    "    entrada = string.split()\n",
    "    entrada = \"-#-\".join(entrada)\n",
    "   \n",
    "    return entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Categorização, filtragem e processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principal dificuldade em relação a esse projeto foram os dados. Apesar de existir um considerável dataset de programas de alunos da disciplina de Programação 1, esses dados são de propriedade dos alunos e dos professores então nesse projeto não posso divulgar nenhum dos dados de treino e de teste. Entretanto todos eles vieram dessas amostras dos alunos de forma anônima. Mais sobre o a quantidade detalhada de cada parte dos dados (treino, teste e validação) em tópicos mais a frente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a filtragem dos dados foram utilizadas duas técnicas, uma utilizando a ferramenta que estou desenvolvendo na pesquisa do mestrado e uma segunda etapa de forma manual em cada uma das amostras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O único processamento feito nos dados foi um parser para ler o código dentro de cada módulo Python e transforma-lo em uma string para a rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Definição da Rede Neural e arquitetura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como este problema involve diretamente leitura de código e <b>tokenization</b> optei por utilizar uma ferramenta que ajuda bastante nessa questão e funcionou bem com a construção da rede, chamada <b>NLTK</b>(natural language tool kit). Essa ferramenta se estende a diversos idiomas, como a linguagem Python é basicamente escrita em inglês e geralmente as variáveis dos programas estão em inglês ou português esse kit se ajustou bem a necessidade do projeto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de definir a Rede Neural propriamente, vale ressaltar que a ideia desse projeto foi baseada na classificação de textos utilizando uma ANN, como foi passado em sala de aula. Nesse caso tratando o código como um comentário que vai ter suas palavras-chave aprendidas e atribuidas pesos para depois determinar se ela se encaixa em determinada classificação ou não. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falaremos agora aqui sobre a arquitetura da rede neural em sí. A ANN (artificial neural network) que foi construida é composta de duas camadas sendo uma delas escondida, e ainda um BOW (bag of words) para ajudar no treinamento da rede. E tem como sua estrutura a imagem que se segue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN 2-layer (1 hidden): \n",
    "![alt text](http://cs231n.github.io/assets/nn1/neural_net.jpeg \"Rede neural\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto a seu funcionamento, nas duas camadas foram utilizadas a função <b>Sigmoid</b> para as duas sinapses. Que foram iniciadas com valores aleatórios com média 0, mas que seriam atualizados pelo algoritmo <b>Gradiente Descendente</b> visto em sala, que tem como objetivo minimizar a função de erro. E  basicamente o que ela faz é a cada iteração dar um peso para cada palavra do bow baseado na presença delas na sentença dada (input)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Construção da Rede Neural e experimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar temos que fazer o importar as bibliotecas que usaremos. <b>NLTK</b> como já foi falado para a manipulação da linguagem e criação de tokens. O <b>json</b> pois as sinapses ficaram em formato json para serem armazenadas. E finalmente <b>glob</b> para manipular arquivos e filtragem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram criadas duas funções auxiliares justamente para essa manipulação de arquivos e processamento do código dos programas que são dados para essa rede neural, retirando aquelas informações desnecessárias nos programas como espaçamento, virgulas e pontos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_files(dir):\n",
    "    list_data = []\n",
    "    files = get_files_names(dir)\n",
    "    for f in files:\n",
    "        with open(f, 'r') as myfile:\n",
    "            data=myfile.read().replace('\\n', ' ')\n",
    "            data=data.replace('.',' ')\n",
    "            data=data.replace('\\t',' ')\n",
    "            data=data.replace('(',' ')\n",
    "            data=data.replace(')',' ')\n",
    "            \n",
    "            data=(\" \".join(data.split()))\n",
    "        list_data.append(data)\n",
    "        \n",
    "    \n",
    "    return list_data\n",
    "\n",
    "\n",
    "def get_files_names(dir):\n",
    "    files = glob.glob(dir + '/*.py')\n",
    "    return files\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos a divisão dos dados em teste e treino. Além da criação das duas classes em questão, nesse caso <b>violation</b> e <b>notviolation</b>. Totalizando 405 no total de dados de treino e 81 para testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 sentences clean of violation for training data\n",
      "135 sentences with violation for training data\n",
      "405 sentences in total training data\n",
      "81 sentences in total test data\n"
     ]
    }
   ],
   "source": [
    "not_violations = get_data_from_files('not_violations')\n",
    "violations = get_data_from_files('violations')\n",
    "test_files = get_data_from_files('test')\n",
    "\n",
    "training_data = []\n",
    "for e in not_violations:\n",
    "    training_data.append({\"class\":\"notviolation\", \"sentence\":e})\n",
    "\n",
    "for e in violations:\n",
    "    training_data.append({\"class\":\"violation\", \"sentence\":e})\n",
    "\n",
    "\n",
    "print (\"%s sentences clean of violation for training data\" % len(not_violations))\n",
    "print (\"%s sentences with violation for training data\" % len(violations))\n",
    "print (\"%s sentences in total training data\" % len(training_data))\n",
    "print (\"%s sentences in total test data\" % len(test_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos então a criação do BOW aqui denominado <b>words</b>, sempre tratando todas as palavras com letras minúsculas e criando seus tokens. Além disso existem uma relação de palavras que caso apareçam serão ignoradas, são elas pontuações da linguagem. <b>Documents</b> aqui trata da relação de presença do token no BOW. No final são removidas as duplicadas através de um <b>set</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 documents\n",
      "2 classes ['notviolation', 'violation']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?',':',',','[',']']\n",
    "\n",
    "for pattern in training_data:\n",
    "    w = nltk.word_tokenize(pattern['sentence'])\n",
    "    words.extend(w)\n",
    "    documents.append((w, pattern['class']))\n",
    "    if pattern['class'] not in classes:\n",
    "        classes.append(pattern['class'])\n",
    "\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "\n",
    "words = list(set(words))\n",
    "classes = list(set(classes))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte organiza-se os dados e conclui a criação do BOW com os <b>documents</b> criados antes. Totalizando 651 palavras no BOW  e as duas classes que esperamos classificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words:  651\n",
      "classes:  2\n"
     ]
    }
   ],
   "source": [
    "training = []\n",
    "output = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    training.append(bag)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    output.append(output_row)\n",
    "\n",
    "print (\"words: \", len(words))\n",
    "print (\"classes: \", len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o BOW concluido um exemplo de como os dados estão organizados é mostrado abaixo. Primeiramente temos o programa em forma de lista de tokens, depois disso o BOW de 0's e 1's para determinar se aquela palavra que está no BOW também está naquela sentença. E por último a qual classe esse programa pertence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-1', 'in', 'in', ']', 'len', 'l1', ':', 'def', 'j', 'j+1', 'return', 'l1', '=', 'j', '[', 'troc', 'l1', '=', 'for', 'j', 'l1', ':', 'rang', '[', ']', 'insere_ordenado_primeiro', '[', ']', 'l1', 'l1', 'j', ']', 'l1', '[', ']', ':', 'for', 'troc', 'j+1', '=', '[', 'if', 'rang', 'l1', 'l1', 'j+1', 'len', ']', '>', '[', 'i', ':', 'l1']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "words_sample = documents[i][0]\n",
    "token_words = [stemmer.stem(word.lower()) for word in words_sample]\n",
    "shuffle(token_words)\n",
    "print (token_words)\n",
    "print (training[i])\n",
    "print (output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte definimos funções extremamentes importantes para os cálculos a cada iteração da rede. Primeiro o importando o <b>numpy</b> que pode fazer operações sobre matrizes de uma forma bem mais eficiente e nos poupa tempo de implementar funções que podem ser black-box. Depois temos a função de ativação que é a mesma para as duas camadas: <b>Sigmoid</b>. A derivada dela também está presente aqui para calcularmos o erro da rede. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas últimas funções são bem importantes pois o <b>bow</b> gera a lista de 0's e 1's que vimos anteriormente no exemplo para um dado programa (tratado como sentença aqui). Já a função <b>think</b> faz o cálculo das sinapses com as camadas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    " \n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "\n",
    "    return(np.array(bag))\n",
    "\n",
    "def think(sentence):\n",
    "    x = bow(sentence.lower(), words)\n",
    "    l0 = x\n",
    "    l1 = sigmoid(np.dot(l0, synapse_0))\n",
    "    l2 = sigmoid(np.dot(l1, synapse_1))\n",
    "    \n",
    "    return l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento utiliza um algoritmo de <b>Gradiente Descendente</b> que foi visto em sala, apenas com algumas alterações para o funcionamento com o BOW e as funções de ativação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa parte especificamente podemos resumir o algoritmo como: Inicialização dos pesos das sinapses de forma aleatoria, para cada iteração calcula-se os valores das camadas e os erros delas em sequencia, se o erro for maior que o da iteração anterior o algoritmo para, se não ele continua até o final das iterações. Atualizando sempre ao final os pesos da sinapses e o gradiente.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No final de tudo as sinapses são armazenadas em um arquivo no formato <b>json</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, y, hidden_neurons=10, alpha=1, iterations=50000):\n",
    "\n",
    "    print (\"Training with %s neurons, alpha:%s \" % (hidden_neurons, str(alpha)) )\n",
    "    print (\"Input matrix: %sx%s    Output matrix: %sx%s\" % (len(X),len(X[0]),1, len(classes)) )\n",
    "    np.random.seed(1)\n",
    "\n",
    "    last_mean_error = 1\n",
    "    synapse_0 = 2*np.random.random((len(X[0]), hidden_neurons)) - 1\n",
    "    synapse_1 = 2*np.random.random((hidden_neurons, len(classes))) - 1\n",
    "\n",
    "    prev_synapse_0_weight_update = np.zeros_like(synapse_0)\n",
    "    prev_synapse_1_weight_update = np.zeros_like(synapse_1)\n",
    "\n",
    "    synapse_0_direction_count = np.zeros_like(synapse_0)\n",
    "    synapse_1_direction_count = np.zeros_like(synapse_1)\n",
    "        \n",
    "    for j in iter(range(iterations+1)):\n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0, synapse_0))\n",
    "        layer_2 = sigmoid(np.dot(layer_1, synapse_1))\n",
    "\n",
    "        layer_2_error = y - layer_2\n",
    "\n",
    "        if (j% 10000) == 0 and j > 5000:\n",
    "            if np.mean(np.abs(layer_2_error)) < last_mean_error:\n",
    "                print (\"delta after \"+str(j)+\" iterations:\" + str(np.mean(np.abs(layer_2_error))) )\n",
    "                last_mean_error = np.mean(np.abs(layer_2_error))\n",
    "            else:\n",
    "                print (\"break:\", np.mean(np.abs(layer_2_error)), \">\", last_mean_error )\n",
    "                break\n",
    "                \n",
    "\n",
    "        layer_2_delta = layer_2_error * sigmoid_output_to_derivative(layer_2)\n",
    "        layer_1_error = layer_2_delta.dot(synapse_1.T)\n",
    "        layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "        \n",
    "        \n",
    "        synapse_1_weight_update = (layer_1.T.dot(layer_2_delta))\n",
    "        synapse_0_weight_update = (layer_0.T.dot(layer_1_delta))\n",
    "        \n",
    "        if(j > 0):\n",
    "            synapse_0_direction_count += np.abs(((synapse_0_weight_update > 0)+0) - ((prev_synapse_0_weight_update > 0) + 0))\n",
    "            synapse_1_direction_count += np.abs(((synapse_1_weight_update > 0)+0) - ((prev_synapse_1_weight_update > 0) + 0))        \n",
    "        \n",
    "        synapse_1 += alpha * synapse_1_weight_update\n",
    "        synapse_0 += alpha * synapse_0_weight_update\n",
    "        \n",
    "        prev_synapse_0_weight_update = synapse_0_weight_update\n",
    "        prev_synapse_1_weight_update = synapse_1_weight_update\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    synapse = {'synapse0': synapse_0.tolist(), 'synapse1': synapse_1.tolist(),\n",
    "               'datetime': now.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "               'words': words,\n",
    "               'classes': classes\n",
    "              }\n",
    "    synapse_file = \"synapses.json\"\n",
    "\n",
    "    with open(synapse_file, 'w') as outfile:\n",
    "        json.dump(synapse, outfile, indent=4, sort_keys=True)\n",
    "    print (\"saved synapses to:\", synapse_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Tunando a rede\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função de predição aqui foi chamada de <b>classify</b> e tem como principio receber uma sentença, que é um programa depois do parser, e aplicar a função  <b>think</b> e retornar sua classificação de forma ordenada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos parâmetros de treino temos <b>hidden_neurons, alpha</b> e <b>iterations</b> que podem ser tunados. Foram utilizadas 3 diferentes configurações para a análise dos resultados. No final de cada um dos diferentes treinos é mostrada a acurácia do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também se tem uma condição de ordenação chamada <b>ERROR_THRESHOLD</b> na qual se for maior que 20% a diferença entre as classes só se imprime a probabilidade da maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(sentence):\n",
    "    results = think(sentence)\n",
    "\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD ] \n",
    "    results.sort(key=lambda x: x[1], reverse=True) \n",
    "    return_results =[[classes[r[0]],r[1]] for r in results]\n",
    "    print (\"classification: %s\" % (return_results))\n",
    "    return return_results\n",
    "\n",
    "test = get_data_from_files('test')\n",
    "test_names = get_files_names('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Configuração - hidden_neurons=10, alpha=1, iterations=50000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 10 neurons, alpha:1 \n",
      "Input matrix: 405x651    Output matrix: 1x2\n",
      "delta after 10000 iterations:0.333333332917\n",
      "delta after 20000 iterations:0.333333332817\n",
      "delta after 30000 iterations:0.333333332657\n",
      "delta after 40000 iterations:0.333333332369\n",
      "delta after 50000 iterations:0.333333331762\n",
      "saved synapses to: synapses.json\n",
      "processing time: 146.9043002128601 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(training)\n",
    "y = np.array(output)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train(X, y, hidden_neurons=10, alpha=1, iterations=50000)\n",
    "\n",
    "# probability threshold\n",
    "ERROR_THRESHOLD = 0.2\n",
    "# load our calculated synapse values\n",
    "synapse_file = 'synapses.json' \n",
    "with open(synapse_file) as data_file: \n",
    "    synapse = json.load(data_file) \n",
    "    synapse_0 = np.asarray(synapse['synapse0']) \n",
    "    synapse_1 = np.asarray(synapse['synapse1'])\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/733e522cba6c8d3fc79cd32546fadf54.py\n",
      "classification: [['notviolation', 0.9999999999999909]]\n",
      "\n",
      "test/04aa2288beeb67289e9d5edaa9c10d41.py\n",
      "classification: [['notviolation', 0.99999999999996581]]\n",
      "\n",
      "test/57327a51d2fb7ab381497f8420b71411.py\n",
      "classification: [['notviolation', 0.99999999999936562]]\n",
      "\n",
      "test/82f2ac914f72771bbfe68ab70ab8c0d1.py\n",
      "classification: [['notviolation', 0.99999999999984879]]\n",
      "\n",
      "test/3757d0261bdeddbc4b79aa52169b7bce.py\n",
      "classification: [['notviolation', 0.99999999999698219]]\n",
      "\n",
      "test/1927ee1c31d541abeae56ec1a2e0fadf.py\n",
      "classification: [['notviolation', 0.99999999993401101]]\n",
      "\n",
      "test/e72f92da1eaa50345ffea0899f9ebbe5.py\n",
      "classification: [['notviolation', 0.9999999999724174]]\n",
      "\n",
      "test/de97abfb65d2b5327965ab99089f56e4.py\n",
      "classification: [['notviolation', 0.99999999999400369]]\n",
      "\n",
      "test/violation_46.py\n",
      "classification: [['notviolation', 0.99999999935359751]]\n",
      "\n",
      "test/violation_33.py\n",
      "classification: [['notviolation', 0.99999999985068344]]\n",
      "\n",
      "test/90036ab09a7539f7dff743e33c6e24cf.py\n",
      "classification: [['notviolation', 0.99999999999998912]]\n",
      "\n",
      "test/f5ea13071009d0f809d5ef1eb6bcaa5c.py\n",
      "classification: [['notviolation', 0.99999999999999534]]\n",
      "\n",
      "test/a41bdacbe0b281d946e7f5c0bd982e74.py\n",
      "classification: [['notviolation', 0.99999999999999423]]\n",
      "\n",
      "test/e209a3d1e1924c06d4b20f423102395b.py\n",
      "classification: [['notviolation', 0.99999999999999845]]\n",
      "\n",
      "test/violation_88.py\n",
      "classification: [['notviolation', 0.99999999999999001]]\n",
      "\n",
      "test/071336a7d3afe253c7c28bbb76fae95d.py\n",
      "classification: [['notviolation', 0.99999999999999956]]\n",
      "\n",
      "test/violation_56.py\n",
      "classification: [['notviolation', 0.99999999994820432]]\n",
      "\n",
      "test/f6fe356a69f5238b0ba28c9de2adb0dc.py\n",
      "classification: [['notviolation', 0.99999999999981704]]\n",
      "\n",
      "test/ecf955aa0aff65c9ff3dab384b2dc330.py\n",
      "classification: [['notviolation', 0.9999999999828757]]\n",
      "\n",
      "test/818f48380af3266ec36938f8eeb0f880.py\n",
      "classification: [['notviolation', 0.9999999999999718]]\n",
      "\n",
      "test/violation_61.py\n",
      "classification: [['notviolation', 0.99999995000331288]]\n",
      "\n",
      "test/violation_9.py\n",
      "classification: [['notviolation', 0.99999999994766431]]\n",
      "\n",
      "test/ec5f4ca1143b9c4a87793566c3b70925.py\n",
      "classification: [['notviolation', 0.99999999999998868]]\n",
      "\n",
      "test/e87b3784e010976419b9bac888091deb.py\n",
      "classification: [['notviolation', 1.0]]\n",
      "\n",
      "test/e369ae277613d899649c63f9b5c7dc9f.py\n",
      "classification: [['notviolation', 0.99999999999999289]]\n",
      "\n",
      "test/violation_29.py\n",
      "classification: [['notviolation', 0.99999985779625211]]\n",
      "\n",
      "test/ed7a7c18d465cd3d38b41787b09ee385.py\n",
      "classification: [['notviolation', 0.99999999999873834]]\n",
      "\n",
      "test/e560dee3413b64ce7c8e2ccfe825e6e9.py\n",
      "classification: [['notviolation', 0.99999999999943223]]\n",
      "\n",
      "test/84362715da96de08a72d12dd32ac3294.py\n",
      "classification: [['notviolation', 0.99999999999998801]]\n",
      "\n",
      "test/ea840dcb1f3b05080302cd790f416f4f.py\n",
      "classification: [['notviolation', 0.99999999996242583]]\n",
      "\n",
      "test/5285352b9458c735ce4c69c9ef016578.py\n",
      "classification: [['notviolation', 0.99999999999996336]]\n",
      "\n",
      "test/violation_94.py\n",
      "classification: [['notviolation', 0.9999999999934488]]\n",
      "\n",
      "test/e36f7758cab2555a9abdcebb3e4bf776.py\n",
      "classification: [['notviolation', 0.99999999987580512]]\n",
      "\n",
      "test/ef799595bfec2ff1ea125c1b03cd8d46.py\n",
      "classification: [['notviolation', 0.99999999988789101]]\n",
      "\n",
      "test/eaec017f6811a0fb32c7c5088c375a66.py\n",
      "classification: [['notviolation', 0.99999999999999933]]\n",
      "\n",
      "test/violation_77.py\n",
      "classification: [['notviolation', 0.99999999999947442]]\n",
      "\n",
      "test/e11ba28ff434ca9b16f95321c2731cf6.py\n",
      "classification: [['notviolation', 0.99999999999962608]]\n",
      "\n",
      "test/e51441ab9197cb667e0679eded25ae17.py\n",
      "classification: [['notviolation', 0.99999999999998535]]\n",
      "\n",
      "test/violation_49.py\n",
      "classification: [['notviolation', 0.99999999999981148]]\n",
      "\n",
      "test/e018102b9f915191e1dc745ed5956073.py\n",
      "classification: [['notviolation', 0.99999999999938938]]\n",
      "\n",
      "test/4bc2c50f89057001c8eb18938c0d1c4c.py\n",
      "classification: [['notviolation', 0.99999999999640221]]\n",
      "\n",
      "test/79e5cae75b7b67773e4e2c930c276f25.py\n",
      "classification: [['notviolation', 0.99999999999999889]]\n",
      "\n",
      "test/3ee678224fe131a5f4c04d80f0e442fd.py\n",
      "classification: [['notviolation', 0.99999999999996891]]\n",
      "\n",
      "test/7042bb9e925f9533201f64f0684c8971.py\n",
      "classification: [['notviolation', 0.99999999999889999]]\n",
      "\n",
      "test/a065ad6fcab08c1a91ff5ba42fbdff51.py\n",
      "classification: [['notviolation', 0.99999999999930567]]\n",
      "\n",
      "test/45088bf95dfb9f11a907f3e4769c6ee8.py\n",
      "classification: [['notviolation', 0.99999999999763944]]\n",
      "\n",
      "test/violation_116.py\n",
      "classification: [['notviolation', 0.99999999999998557]]\n",
      "\n",
      "test/violation_86.py\n",
      "classification: [['notviolation', 0.99999999999968225]]\n",
      "\n",
      "test/violation_19.py\n",
      "classification: [['notviolation', 0.99999999999807687]]\n",
      "\n",
      "test/edff3e8a4ae70a2ac733514bff96f9ae.py\n",
      "classification: [['notviolation', 0.99999999941706297]]\n",
      "\n",
      "test/violation_5.py\n",
      "classification: [['notviolation', 0.99999999991003286]]\n",
      "\n",
      "test/e6b51a6898f1b47574bdd5a779b0f72a.py\n",
      "classification: [['notviolation', 0.99999999999999978]]\n",
      "\n",
      "test/83d28664949eea47f3656d96ce78af3f.py\n",
      "classification: [['notviolation', 0.99999999999998734]]\n",
      "\n",
      "test/991d637387ff2221522ea4544c19cb17.py\n",
      "classification: [['notviolation', 0.99999999999990563]]\n",
      "\n",
      "test/f7d9980b18038b5445f8a66a0d5a5bc7.py\n",
      "classification: [['notviolation', 0.99999999992189825]]\n",
      "\n",
      "test/violation_39.py\n",
      "classification: [['notviolation', 0.99999999997276756]]\n",
      "\n",
      "test/violation_115.py\n",
      "classification: [['notviolation', 0.99999999743074941]]\n",
      "\n",
      "test/e5c18c7b4f36b58686fb6383a362cc21.py\n",
      "classification: [['notviolation', 0.99999999996965361]]\n",
      "\n",
      "test/e3f25444efcd0c539599527724dede30.py\n",
      "classification: [['notviolation', 0.99999999999997025]]\n",
      "\n",
      "test/violation_78.py\n",
      "classification: [['notviolation', 0.99999999996024513]]\n",
      "\n",
      "test/a3c33ff5e32c5cc86a45995dc6bf3600.py\n",
      "classification: [['notviolation', 0.99999999990890176]]\n",
      "\n",
      "test/violation_60.py\n",
      "classification: [['notviolation', 0.99999999999440847]]\n",
      "\n",
      "test/violation_92.py\n",
      "classification: [['notviolation', 0.99999999999994249]]\n",
      "\n",
      "test/decbb83720ea677c38fd6187f12005fc.py\n",
      "classification: [['notviolation', 0.99999999999984324]]\n",
      "\n",
      "test/936b899a67fb49dd694918c6642a6e21.py\n",
      "classification: [['notviolation', 0.99999999999999112]]\n",
      "\n",
      "test/3911e28750032216264878ffca670235.py\n",
      "classification: [['notviolation', 0.99999999999998868]]\n",
      "\n",
      "test/violation_70.py\n",
      "classification: [['notviolation', 0.9999999999480742]]\n",
      "\n",
      "test/88b1f0fc56e69d22ebfba40812b5d017.py\n",
      "classification: [['notviolation', 0.99999999999784772]]\n",
      "\n",
      "test/violation_21.py\n",
      "classification: [['notviolation', 0.99999999999982436]]\n",
      "\n",
      "test/98515371f4cdaf85b2b0bf95e760fe4b.py\n",
      "classification: [['notviolation', 0.99999999997670463]]\n",
      "\n",
      "test/ece23beb70bce49ae536114de5ca48b6.py\n",
      "classification: [['notviolation', 0.99999999999575628]]\n",
      "\n",
      "test/violation_65.py\n",
      "classification: [['notviolation', 0.99999999815209795]]\n",
      "\n",
      "test/violation_23.py\n",
      "classification: [['notviolation', 0.99999999999994738]]\n",
      "\n",
      "test/violation_18.py\n",
      "classification: [['notviolation', 0.99999999991425614]]\n",
      "\n",
      "test/661b080648ccde6ac516df7abde52eea.py\n",
      "classification: [['notviolation', 0.99999999999642686]]\n",
      "\n",
      "test/ee4f3178893e43ec0fdf80f54f274eba.py\n",
      "classification: [['notviolation', 0.99999999994573852]]\n",
      "\n",
      "test/3122876d784fe57879368b8062e4fb36.py\n",
      "classification: [['notviolation', 0.99999999999999978]]\n",
      "\n",
      "test/990d8721e539efef24b982433317df0c.py\n",
      "classification: [['notviolation', 0.99999999999845612]]\n",
      "\n",
      "test/e75421b391328a87801cfaba5f2e6972.py\n",
      "classification: [['notviolation', 0.99999999999983591]]\n",
      "\n",
      "test/a7eedb6ca2ffa15e106742881dfa9023.py\n",
      "classification: [['notviolation', 0.99999999999998979]]\n",
      "\n",
      "test/f2f6761ebe477d9894da4a82d6efbe6d.py\n",
      "classification: [['notviolation', 0.99999999999472555]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test_names[i])\n",
    "    result = classify(test[i])\n",
    "    \n",
    "    if ('violation' in test_names[i] and result[0][0] == 'violation') or \\\n",
    "     ('violation' not in test_names[i] and result[0][0] == 'notviolation'):\n",
    "        accuracy += 1.0\n",
    "    \n",
    "    print() \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.37037037037037%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s%%\" %(accuracy/len(test) * 100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Configuração - hidden_neurons=15, alpha=0.1, iterations=100000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 15 neurons, alpha:0.1 \n",
      "Input matrix: 405x651    Output matrix: 1x2\n",
      "delta after 10000 iterations:0.00372541230022\n",
      "delta after 20000 iterations:0.00332812946533\n",
      "delta after 30000 iterations:0.00315700676935\n",
      "delta after 40000 iterations:0.00305664947844\n",
      "delta after 50000 iterations:0.00298903141037\n",
      "delta after 60000 iterations:0.00293970339687\n",
      "delta after 70000 iterations:0.00290182789618\n",
      "delta after 80000 iterations:0.00287170164791\n",
      "delta after 90000 iterations:0.002847132488\n",
      "delta after 100000 iterations:0.00282674750057\n",
      "saved synapses to: synapses.json\n",
      "processing time: 339.45823335647583 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = np.array(training)\n",
    "y = np.array(output)\n",
    "\n",
    "start_time = time.time()\n",
    "train(X, y, hidden_neurons=15, alpha=0.1, iterations=100000)\n",
    "\n",
    "# probability threshold\n",
    "ERROR_THRESHOLD = 0.2\n",
    "# load our calculated synapse values\n",
    "synapse_file = 'synapses.json' \n",
    "with open(synapse_file) as data_file: \n",
    "    synapse = json.load(data_file) \n",
    "    synapse_0 = np.asarray(synapse['synapse0']) \n",
    "    synapse_1 = np.asarray(synapse['synapse1'])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/733e522cba6c8d3fc79cd32546fadf54.py\n",
      "classification: [['notviolation', 0.99999994681454385]]\n",
      "\n",
      "test/04aa2288beeb67289e9d5edaa9c10d41.py\n",
      "classification: [['notviolation', 0.99943335762820074]]\n",
      "\n",
      "test/57327a51d2fb7ab381497f8420b71411.py\n",
      "classification: [['notviolation', 0.99898651805160643]]\n",
      "\n",
      "test/82f2ac914f72771bbfe68ab70ab8c0d1.py\n",
      "classification: [['notviolation', 0.99974351535192107]]\n",
      "\n",
      "test/3757d0261bdeddbc4b79aa52169b7bce.py\n",
      "classification: [['notviolation', 0.98429955334866193]]\n",
      "\n",
      "test/1927ee1c31d541abeae56ec1a2e0fadf.py\n",
      "classification: [['notviolation', 0.99919815305133086]]\n",
      "\n",
      "test/e72f92da1eaa50345ffea0899f9ebbe5.py\n",
      "classification: [['notviolation', 0.99999973751478011]]\n",
      "\n",
      "test/de97abfb65d2b5327965ab99089f56e4.py\n",
      "classification: [['notviolation', 0.99999984746624127]]\n",
      "\n",
      "test/violation_46.py\n",
      "classification: [['violation', 0.99999585619601428]]\n",
      "\n",
      "test/violation_33.py\n",
      "classification: [['violation', 0.99991849823663637]]\n",
      "\n",
      "test/90036ab09a7539f7dff743e33c6e24cf.py\n",
      "classification: [['notviolation', 0.99995988876582254]]\n",
      "\n",
      "test/f5ea13071009d0f809d5ef1eb6bcaa5c.py\n",
      "classification: [['notviolation', 0.9999991789963979]]\n",
      "\n",
      "test/a41bdacbe0b281d946e7f5c0bd982e74.py\n",
      "classification: [['notviolation', 0.99998059104826098]]\n",
      "\n",
      "test/e209a3d1e1924c06d4b20f423102395b.py\n",
      "classification: [['notviolation', 0.99999999641332105]]\n",
      "\n",
      "test/violation_88.py\n",
      "classification: [['notviolation', 0.91595993278459642]]\n",
      "\n",
      "test/071336a7d3afe253c7c28bbb76fae95d.py\n",
      "classification: [['notviolation', 0.999999829064523]]\n",
      "\n",
      "test/violation_56.py\n",
      "classification: [['violation', 0.999993650991718]]\n",
      "\n",
      "test/f6fe356a69f5238b0ba28c9de2adb0dc.py\n",
      "classification: [['notviolation', 0.99999957534311079]]\n",
      "\n",
      "test/ecf955aa0aff65c9ff3dab384b2dc330.py\n",
      "classification: [['notviolation', 0.99999795901970456]]\n",
      "\n",
      "test/818f48380af3266ec36938f8eeb0f880.py\n",
      "classification: [['notviolation', 0.99999789954262008]]\n",
      "\n",
      "test/violation_61.py\n",
      "classification: [['notviolation', 0.68931680100282089], ['violation', 0.29610388474704774]]\n",
      "\n",
      "test/violation_9.py\n",
      "classification: [['violation', 0.99994664641086028]]\n",
      "\n",
      "test/ec5f4ca1143b9c4a87793566c3b70925.py\n",
      "classification: [['notviolation', 0.99999669454960094]]\n",
      "\n",
      "test/e87b3784e010976419b9bac888091deb.py\n",
      "classification: [['notviolation', 0.99999981900816814]]\n",
      "\n",
      "test/e369ae277613d899649c63f9b5c7dc9f.py\n",
      "classification: [['notviolation', 0.99997260997733894]]\n",
      "\n",
      "test/violation_29.py\n",
      "classification: [['violation', 0.99999701681347608]]\n",
      "\n",
      "test/ed7a7c18d465cd3d38b41787b09ee385.py\n",
      "classification: [['notviolation', 0.84444646789767508]]\n",
      "\n",
      "test/e560dee3413b64ce7c8e2ccfe825e6e9.py\n",
      "classification: [['notviolation', 0.99990296223259323]]\n",
      "\n",
      "test/84362715da96de08a72d12dd32ac3294.py\n",
      "classification: [['notviolation', 0.99900464595950511]]\n",
      "\n",
      "test/ea840dcb1f3b05080302cd790f416f4f.py\n",
      "classification: [['violation', 0.87318311705839657]]\n",
      "\n",
      "test/5285352b9458c735ce4c69c9ef016578.py\n",
      "classification: [['notviolation', 0.99994602298597957]]\n",
      "\n",
      "test/violation_94.py\n",
      "classification: [['violation', 0.53933534836393204], ['notviolation', 0.45794668267613103]]\n",
      "\n",
      "test/e36f7758cab2555a9abdcebb3e4bf776.py\n",
      "classification: [['notviolation', 0.99897574137833689]]\n",
      "\n",
      "test/ef799595bfec2ff1ea125c1b03cd8d46.py\n",
      "classification: [['notviolation', 0.99974510661540306]]\n",
      "\n",
      "test/eaec017f6811a0fb32c7c5088c375a66.py\n",
      "classification: [['notviolation', 0.95975751867214021]]\n",
      "\n",
      "test/violation_77.py\n",
      "classification: [['violation', 0.99050922167641853]]\n",
      "\n",
      "test/e11ba28ff434ca9b16f95321c2731cf6.py\n",
      "classification: [['notviolation', 0.9999558353776129]]\n",
      "\n",
      "test/e51441ab9197cb667e0679eded25ae17.py\n",
      "classification: [['notviolation', 0.9999999215360954]]\n",
      "\n",
      "test/violation_49.py\n",
      "classification: [['violation', 0.80254751122069412]]\n",
      "\n",
      "test/e018102b9f915191e1dc745ed5956073.py\n",
      "classification: [['notviolation', 0.99988817339788172]]\n",
      "\n",
      "test/4bc2c50f89057001c8eb18938c0d1c4c.py\n",
      "classification: [['notviolation', 0.99999898845754975]]\n",
      "\n",
      "test/79e5cae75b7b67773e4e2c930c276f25.py\n",
      "classification: [['notviolation', 0.99994946189399037]]\n",
      "\n",
      "test/3ee678224fe131a5f4c04d80f0e442fd.py\n",
      "classification: [['notviolation', 0.99998481536549244]]\n",
      "\n",
      "test/7042bb9e925f9533201f64f0684c8971.py\n",
      "classification: [['notviolation', 0.99999921683670767]]\n",
      "\n",
      "test/a065ad6fcab08c1a91ff5ba42fbdff51.py\n",
      "classification: [['violation', 0.87014240286518751]]\n",
      "\n",
      "test/45088bf95dfb9f11a907f3e4769c6ee8.py\n",
      "classification: [['notviolation', 0.99997862474653454]]\n",
      "\n",
      "test/violation_116.py\n",
      "classification: [['violation', 0.99986529551611325]]\n",
      "\n",
      "test/violation_86.py\n",
      "classification: [['violation', 0.98353063925709605]]\n",
      "\n",
      "test/violation_19.py\n",
      "classification: [['violation', 0.9999519294738124]]\n",
      "\n",
      "test/edff3e8a4ae70a2ac733514bff96f9ae.py\n",
      "classification: [['notviolation', 0.97080868613614579]]\n",
      "\n",
      "test/violation_5.py\n",
      "classification: [['violation', 0.99980854134043429]]\n",
      "\n",
      "test/e6b51a6898f1b47574bdd5a779b0f72a.py\n",
      "classification: [['notviolation', 0.99971308748625709]]\n",
      "\n",
      "test/83d28664949eea47f3656d96ce78af3f.py\n",
      "classification: [['notviolation', 0.99998584285694003]]\n",
      "\n",
      "test/991d637387ff2221522ea4544c19cb17.py\n",
      "classification: [['notviolation', 0.87806506200732604]]\n",
      "\n",
      "test/f7d9980b18038b5445f8a66a0d5a5bc7.py\n",
      "classification: [['notviolation', 0.99943087099488759]]\n",
      "\n",
      "test/violation_39.py\n",
      "classification: [['notviolation', 0.9975926413047187]]\n",
      "\n",
      "test/violation_115.py\n",
      "classification: [['violation', 0.99868224050311505]]\n",
      "\n",
      "test/e5c18c7b4f36b58686fb6383a362cc21.py\n",
      "classification: [['notviolation', 0.99999864494113966]]\n",
      "\n",
      "test/e3f25444efcd0c539599527724dede30.py\n",
      "classification: [['notviolation', 0.99999440317646926]]\n",
      "\n",
      "test/violation_78.py\n",
      "classification: [['notviolation', 0.99237062970912138]]\n",
      "\n",
      "test/a3c33ff5e32c5cc86a45995dc6bf3600.py\n",
      "classification: [['notviolation', 0.99976902675281609]]\n",
      "\n",
      "test/violation_60.py\n",
      "classification: [['violation', 0.99994896139770328]]\n",
      "\n",
      "test/violation_92.py\n",
      "classification: [['notviolation', 0.97193864007785735]]\n",
      "\n",
      "test/decbb83720ea677c38fd6187f12005fc.py\n",
      "classification: [['notviolation', 0.89000328463750911]]\n",
      "\n",
      "test/936b899a67fb49dd694918c6642a6e21.py\n",
      "classification: [['notviolation', 0.99999604193173552]]\n",
      "\n",
      "test/3911e28750032216264878ffca670235.py\n",
      "classification: [['notviolation', 0.99999849405959973]]\n",
      "\n",
      "test/violation_70.py\n",
      "classification: [['violation', 0.99999878857366775]]\n",
      "\n",
      "test/88b1f0fc56e69d22ebfba40812b5d017.py\n",
      "classification: [['notviolation', 0.9999999523834342]]\n",
      "\n",
      "test/violation_21.py\n",
      "classification: [['violation', 0.99919311500452179]]\n",
      "\n",
      "test/98515371f4cdaf85b2b0bf95e760fe4b.py\n",
      "classification: [['notviolation', 0.99999965510983124]]\n",
      "\n",
      "test/ece23beb70bce49ae536114de5ca48b6.py\n",
      "classification: [['notviolation', 0.99999999097623371]]\n",
      "\n",
      "test/violation_65.py\n",
      "classification: [['notviolation', 0.95574254427277061]]\n",
      "\n",
      "test/violation_23.py\n",
      "classification: [['violation', 0.9999983544822254]]\n",
      "\n",
      "test/violation_18.py\n",
      "classification: [['violation', 0.99999852221950736]]\n",
      "\n",
      "test/661b080648ccde6ac516df7abde52eea.py\n",
      "classification: [['notviolation', 0.99999614860748176]]\n",
      "\n",
      "test/ee4f3178893e43ec0fdf80f54f274eba.py\n",
      "classification: [['notviolation', 0.99998952019207188]]\n",
      "\n",
      "test/3122876d784fe57879368b8062e4fb36.py\n",
      "classification: [['notviolation', 0.99976039233463965]]\n",
      "\n",
      "test/990d8721e539efef24b982433317df0c.py\n",
      "classification: [['notviolation', 0.99993509200916186]]\n",
      "\n",
      "test/e75421b391328a87801cfaba5f2e6972.py\n",
      "classification: [['notviolation', 0.99996353732945853]]\n",
      "\n",
      "test/a7eedb6ca2ffa15e106742881dfa9023.py\n",
      "classification: [['notviolation', 0.99985194607975736]]\n",
      "\n",
      "test/f2f6761ebe477d9894da4a82d6efbe6d.py\n",
      "classification: [['notviolation', 0.99996489677605394]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test_names[i])\n",
    "    result = classify(test[i])\n",
    "    \n",
    "    if ('violation' in test_names[i] and result[0][0] == 'violation') or \\\n",
    "     ('violation' not in test_names[i] and result[0][0] == 'notviolation'):\n",
    "        accuracy += 1.0\n",
    "    \n",
    "    print() \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.12345679012346%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s%%\" %(accuracy/len(test) * 100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Configuração - hidden_neurons=25, alpha=0.01, iterations=100000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 25 neurons, alpha:0.01 \n",
      "Input matrix: 405x651    Output matrix: 1x2\n",
      "delta after 10000 iterations:0.00887689718091\n",
      "delta after 20000 iterations:0.00343929900577\n",
      "delta after 30000 iterations:0.00261931654725\n",
      "delta after 40000 iterations:0.00219676206446\n",
      "delta after 50000 iterations:0.00192663965152\n",
      "delta after 60000 iterations:0.00173472807108\n",
      "delta after 70000 iterations:0.00158934630629\n",
      "delta after 80000 iterations:0.00147431934455\n",
      "delta after 90000 iterations:0.00138039499209\n",
      "delta after 100000 iterations:0.00130184300606\n",
      "saved synapses to: synapses.json\n",
      "processing time: 548.1557412147522 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "X = np.array(training)\n",
    "y = np.array(output)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train(X, y, hidden_neurons=25, alpha=0.01, iterations=100000)\n",
    "\n",
    "# probability threshold\n",
    "ERROR_THRESHOLD = 0.2\n",
    "# load our calculated synapse values\n",
    "synapse_file = 'synapses.json' \n",
    "with open(synapse_file) as data_file: \n",
    "    synapse = json.load(data_file) \n",
    "    synapse_0 = np.asarray(synapse['synapse0']) \n",
    "    synapse_1 = np.asarray(synapse['synapse1'])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/733e522cba6c8d3fc79cd32546fadf54.py\n",
      "classification: [['notviolation', 0.99988149683810013]]\n",
      "\n",
      "test/04aa2288beeb67289e9d5edaa9c10d41.py\n",
      "classification: [['notviolation', 0.97996282279966085]]\n",
      "\n",
      "test/57327a51d2fb7ab381497f8420b71411.py\n",
      "classification: [['notviolation', 0.9794532133536501]]\n",
      "\n",
      "test/82f2ac914f72771bbfe68ab70ab8c0d1.py\n",
      "classification: [['notviolation', 0.99968959741189811]]\n",
      "\n",
      "test/3757d0261bdeddbc4b79aa52169b7bce.py\n",
      "classification: [['notviolation', 0.94392288357704845]]\n",
      "\n",
      "test/1927ee1c31d541abeae56ec1a2e0fadf.py\n",
      "classification: [['notviolation', 0.99901984844366587]]\n",
      "\n",
      "test/e72f92da1eaa50345ffea0899f9ebbe5.py\n",
      "classification: [['notviolation', 0.99999917863605792]]\n",
      "\n",
      "test/de97abfb65d2b5327965ab99089f56e4.py\n",
      "classification: [['notviolation', 0.99988575270400248]]\n",
      "\n",
      "test/violation_46.py\n",
      "classification: [['violation', 0.99986744066675404]]\n",
      "\n",
      "test/violation_33.py\n",
      "classification: [['violation', 0.99736829923059334]]\n",
      "\n",
      "test/90036ab09a7539f7dff743e33c6e24cf.py\n",
      "classification: [['notviolation', 0.9996323570182517]]\n",
      "\n",
      "test/f5ea13071009d0f809d5ef1eb6bcaa5c.py\n",
      "classification: [['notviolation', 0.99996363355862072]]\n",
      "\n",
      "test/a41bdacbe0b281d946e7f5c0bd982e74.py\n",
      "classification: [['notviolation', 0.99992073866379017]]\n",
      "\n",
      "test/e209a3d1e1924c06d4b20f423102395b.py\n",
      "classification: [['notviolation', 0.99972973139873522]]\n",
      "\n",
      "test/violation_88.py\n",
      "classification: [['notviolation', 0.85447623381305016]]\n",
      "\n",
      "test/071336a7d3afe253c7c28bbb76fae95d.py\n",
      "classification: [['notviolation', 0.99937722411596208]]\n",
      "\n",
      "test/violation_56.py\n",
      "classification: [['violation', 0.96507629144776597]]\n",
      "\n",
      "test/f6fe356a69f5238b0ba28c9de2adb0dc.py\n",
      "classification: [['notviolation', 0.99923710517489817]]\n",
      "\n",
      "test/ecf955aa0aff65c9ff3dab384b2dc330.py\n",
      "classification: [['notviolation', 0.99983572726963776]]\n",
      "\n",
      "test/818f48380af3266ec36938f8eeb0f880.py\n",
      "classification: [['notviolation', 0.99992329557603088]]\n",
      "\n",
      "test/violation_61.py\n",
      "classification: [['violation', 0.94374608281052785]]\n",
      "\n",
      "test/violation_9.py\n",
      "classification: [['violation', 0.99993851129745126]]\n",
      "\n",
      "test/ec5f4ca1143b9c4a87793566c3b70925.py\n",
      "classification: [['notviolation', 0.9998596877195417]]\n",
      "\n",
      "test/e87b3784e010976419b9bac888091deb.py\n",
      "classification: [['notviolation', 0.99984228668294373]]\n",
      "\n",
      "test/e369ae277613d899649c63f9b5c7dc9f.py\n",
      "classification: [['notviolation', 0.99962864055125578]]\n",
      "\n",
      "test/violation_29.py\n",
      "classification: [['violation', 0.99983292931343204]]\n",
      "\n",
      "test/ed7a7c18d465cd3d38b41787b09ee385.py\n",
      "classification: [['notviolation', 0.9688069486439056]]\n",
      "\n",
      "test/e560dee3413b64ce7c8e2ccfe825e6e9.py\n",
      "classification: [['notviolation', 0.99996465203769447]]\n",
      "\n",
      "test/84362715da96de08a72d12dd32ac3294.py\n",
      "classification: [['notviolation', 0.99947144659214071]]\n",
      "\n",
      "test/ea840dcb1f3b05080302cd790f416f4f.py\n",
      "classification: [['notviolation', 0.8399737856101771]]\n",
      "\n",
      "test/5285352b9458c735ce4c69c9ef016578.py\n",
      "classification: [['notviolation', 0.99977650525419814]]\n",
      "\n",
      "test/violation_94.py\n",
      "classification: [['violation', 0.98722413027408651]]\n",
      "\n",
      "test/e36f7758cab2555a9abdcebb3e4bf776.py\n",
      "classification: [['notviolation', 0.99725240560799655]]\n",
      "\n",
      "test/ef799595bfec2ff1ea125c1b03cd8d46.py\n",
      "classification: [['notviolation', 0.99527504290768376]]\n",
      "\n",
      "test/eaec017f6811a0fb32c7c5088c375a66.py\n",
      "classification: [['notviolation', 0.97141933607188524]]\n",
      "\n",
      "test/violation_77.py\n",
      "classification: [['violation', 0.72776397992253272], ['notviolation', 0.27320376231730203]]\n",
      "\n",
      "test/e11ba28ff434ca9b16f95321c2731cf6.py\n",
      "classification: [['notviolation', 0.99906132154609439]]\n",
      "\n",
      "test/e51441ab9197cb667e0679eded25ae17.py\n",
      "classification: [['notviolation', 0.99997831538555748]]\n",
      "\n",
      "test/violation_49.py\n",
      "classification: [['notviolation', 0.90172181533624984]]\n",
      "\n",
      "test/e018102b9f915191e1dc745ed5956073.py\n",
      "classification: [['notviolation', 0.99931107204644098]]\n",
      "\n",
      "test/4bc2c50f89057001c8eb18938c0d1c4c.py\n",
      "classification: [['notviolation', 0.99997076138507535]]\n",
      "\n",
      "test/79e5cae75b7b67773e4e2c930c276f25.py\n",
      "classification: [['notviolation', 0.99942967677865591]]\n",
      "\n",
      "test/3ee678224fe131a5f4c04d80f0e442fd.py\n",
      "classification: [['notviolation', 0.99868217536679604]]\n",
      "\n",
      "test/7042bb9e925f9533201f64f0684c8971.py\n",
      "classification: [['notviolation', 0.99928258810908355]]\n",
      "\n",
      "test/a065ad6fcab08c1a91ff5ba42fbdff51.py\n",
      "classification: [['violation', 0.58866869082283957], ['notviolation', 0.40160756384375979]]\n",
      "\n",
      "test/45088bf95dfb9f11a907f3e4769c6ee8.py\n",
      "classification: [['notviolation', 0.99978817355266292]]\n",
      "\n",
      "test/violation_116.py\n",
      "classification: [['violation', 0.9998185827932573]]\n",
      "\n",
      "test/violation_86.py\n",
      "classification: [['violation', 0.99477141710083739]]\n",
      "\n",
      "test/violation_19.py\n",
      "classification: [['violation', 0.99764665972540012]]\n",
      "\n",
      "test/edff3e8a4ae70a2ac733514bff96f9ae.py\n",
      "classification: [['notviolation', 0.88563303106751567]]\n",
      "\n",
      "test/violation_5.py\n",
      "classification: [['violation', 0.93731257600577444]]\n",
      "\n",
      "test/e6b51a6898f1b47574bdd5a779b0f72a.py\n",
      "classification: [['notviolation', 0.99849942095646005]]\n",
      "\n",
      "test/83d28664949eea47f3656d96ce78af3f.py\n",
      "classification: [['notviolation', 0.99964092916833713]]\n",
      "\n",
      "test/991d637387ff2221522ea4544c19cb17.py\n",
      "classification: [['notviolation', 0.98421650124932958]]\n",
      "\n",
      "test/f7d9980b18038b5445f8a66a0d5a5bc7.py\n",
      "classification: [['notviolation', 0.99796767377017959]]\n",
      "\n",
      "test/violation_39.py\n",
      "classification: [['notviolation', 0.9995063882209777]]\n",
      "\n",
      "test/violation_115.py\n",
      "classification: [['violation', 0.99584876904017439]]\n",
      "\n",
      "test/e5c18c7b4f36b58686fb6383a362cc21.py\n",
      "classification: [['notviolation', 0.99987635289105414]]\n",
      "\n",
      "test/e3f25444efcd0c539599527724dede30.py\n",
      "classification: [['notviolation', 0.99945479164107165]]\n",
      "\n",
      "test/violation_78.py\n",
      "classification: [['notviolation', 0.51199707426664565], ['violation', 0.43357343103334234]]\n",
      "\n",
      "test/a3c33ff5e32c5cc86a45995dc6bf3600.py\n",
      "classification: [['notviolation', 0.99945943540319815]]\n",
      "\n",
      "test/violation_60.py\n",
      "classification: [['violation', 0.89740545964612328]]\n",
      "\n",
      "test/violation_92.py\n",
      "classification: [['notviolation', 0.99954305969409374]]\n",
      "\n",
      "test/decbb83720ea677c38fd6187f12005fc.py\n",
      "classification: [['notviolation', 0.83187412120284632]]\n",
      "\n",
      "test/936b899a67fb49dd694918c6642a6e21.py\n",
      "classification: [['notviolation', 0.99983796674161818]]\n",
      "\n",
      "test/3911e28750032216264878ffca670235.py\n",
      "classification: [['notviolation', 0.99932710148661374]]\n",
      "\n",
      "test/violation_70.py\n",
      "classification: [['violation', 0.99875148062989094]]\n",
      "\n",
      "test/88b1f0fc56e69d22ebfba40812b5d017.py\n",
      "classification: [['notviolation', 0.99999611149520584]]\n",
      "\n",
      "test/violation_21.py\n",
      "classification: [['violation', 0.7613370522184959], ['notviolation', 0.27070092255420686]]\n",
      "\n",
      "test/98515371f4cdaf85b2b0bf95e760fe4b.py\n",
      "classification: [['notviolation', 0.99135692363056138]]\n",
      "\n",
      "test/ece23beb70bce49ae536114de5ca48b6.py\n",
      "classification: [['notviolation', 0.99677991401236687]]\n",
      "\n",
      "test/violation_65.py\n",
      "classification: [['notviolation', 0.97158991068952971]]\n",
      "\n",
      "test/violation_23.py\n",
      "classification: [['violation', 0.9999966769958254]]\n",
      "\n",
      "test/violation_18.py\n",
      "classification: [['violation', 0.99991663413235643]]\n",
      "\n",
      "test/661b080648ccde6ac516df7abde52eea.py\n",
      "classification: [['notviolation', 0.99997940894103898]]\n",
      "\n",
      "test/ee4f3178893e43ec0fdf80f54f274eba.py\n",
      "classification: [['notviolation', 0.99985007874390064]]\n",
      "\n",
      "test/3122876d784fe57879368b8062e4fb36.py\n",
      "classification: [['notviolation', 0.99945270490821581]]\n",
      "\n",
      "test/990d8721e539efef24b982433317df0c.py\n",
      "classification: [['notviolation', 0.99996346858638341]]\n",
      "\n",
      "test/e75421b391328a87801cfaba5f2e6972.py\n",
      "classification: [['notviolation', 0.99959835538883524]]\n",
      "\n",
      "test/a7eedb6ca2ffa15e106742881dfa9023.py\n",
      "classification: [['notviolation', 0.99936223423874448]]\n",
      "\n",
      "test/f2f6761ebe477d9894da4a82d6efbe6d.py\n",
      "classification: [['notviolation', 0.99920629847077913]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test_names[i])\n",
    "    result = classify(test[i])\n",
    "    \n",
    "    if ('violation' in test_names[i] and result[0][0] == 'violation') or \\\n",
    "     ('violation' not in test_names[i] and result[0][0] == 'notviolation'):\n",
    "        accuracy += 1.0\n",
    "    \n",
    "    print() \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.12345679012346%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s%%\" %(accuracy/len(test) * 100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando os números apresentados acima podemos concluir que o melhor resultado foi obtido com a configuração 3 na qual existe uma maior quantidade de neurônios e o alpha, que são os passos do gradiente, é menor, o que se ajusta com a quantidade de iterações. Esta última configuração conseguiu classificar <b>91,35%</b> dos casos de testes, o que é impressionante dado que a quantidade de dados de treino para violações é a metade das não-violações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entretanto algumas ameaças a validade devem ser ressaltadas, como o dataset reduzido por ser somente de uma unidade da disciplina, e que como só se tem duas camadas na rede a medida que se aumentam as iterações e o número de neurônios o tempo de treino aumenta consideravelmente e em alguns cenários de configuração se tornou impraticável para demonstração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'demo_function', 'list', ':', 'cont', '=', '0', 'for', 'i', 'in', 'rang', 'len', 'list', ':', 'if', 'list', '[', 'i', ']', '==', \"'e\", \"'\", ':', 'cont', '+=', '1', 'return', 'cont']\n",
      "\n",
      "demo/demo_file_program.py\n",
      "classification: [['notviolation', 0.8332291482694385], ['violation', 0.20242930339405568]]\n"
     ]
    }
   ],
   "source": [
    "demo = get_data_from_files('demo')\n",
    "demo_file = get_files_names('demo')\n",
    "\n",
    "for i in range(len(demo)):\n",
    "    print(clean_up_sentence(demo[i]))\n",
    "    print()\n",
    "    print(demo_file[i])\n",
    "    classify(demo[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
